---
layout: page
title: "Projects"
teaser: "This is a list of projects I worked for"
permalink: "/research/projects/"
header:
    image_fullwidth: "mediaplayer_js-home.jpg"
categories:
  -
tags:
  - machine learning, bioacoustics, animal communication, fatml, fairness, interpretability, audio signal processing, music information retrieval, research, groove, classical music, source separation, transcription
---
### 2023-now
[![Earth Species Project](https://7wdata.be/wp-content/uploads/2021/04/Earth-Species-Project-Logo.jpg)][5]
ESP is a non-profit organization targeting a goal that may have sounded impossible a few years ago: to decode animal communication. The key idea is to use the latest advances in machine learning, in particular foundation models and to apply them across a few species. The challenge is that the field is lacking the ground truth data that exists for the human domain: think of the amount of data on the internet encompassing the whole human knowledge or the amount of speech data available for training. I have been working on training denoising models for animal vocalizations without having access to clean data (i.e. unsupervised denoising) and generative large language models. 

### 2020-2023
[![Senior Researcher at MTG](https://www.upf.edu/documents/8071534/8177261/MTG_logo-07.png)][4]
After Seville, I moved back to Barcelona to work at the Music Technology Group (MTG) as a Senior Researcher. I was funded by the Next-Core and MusicAI projects. I was involved in a few R&D projects regarding transfer learning to a range of music classification tasks. I managed a team of interns to work on developing the mirdata and soundata libraries. I took part in writing a few Spanish project proposals which were accepted. I helped organizing the ISMIR 2022 conference.
I co-supervised 2 PhD students and collaborated with several other students on papers published at ISMIR, DAFX, SMC, ICASSP, ACM Multimedia. I adapted the Music Information Retrieval Master's Course for the deep learning era. Each year I suppervised 4 Master's thesis. At least one of them was published as a conference paper. It was quite intense but a great experience. It was rewarding to see people grow from being new to the field to develop their own paths and careers. I learned a lot particularly on the management side. 

### 2018-2020
[![Humaint](https://ec.europa.eu/jrc/communities/sites/jrccties/files/styles/community_banner/public/banner_0.jpg)][3]

HUMAINT is an interdisciplinary project within the JRC's Centre for Advanced Studies aiming to understand the impact of machine intelligence on human behaviour, with a focus on cognitive and socio-emotional capabilities and decision making.

Research topics: fairness, accountability and transparency, deep learning, human-robot interaction, children's robotics, algorithm-supported decision making, data-driven policy making, music and creativity.

The project involves a core team of researchers plus a community of experts in cognitive science, machine learning, human-computer interaction and economics.

### 2013-2017
[![Phenicx]({{ site.url }}/images/Logo_Phenicx-04.gif)][1]

PHENICX is a collaborative research project, partially funded by the European commission. In this project, academic researchers, music institutions, musicians and up-and-coming technology companies join forces. Our mission is to make use of all the richness around classical music: the sound you can hear, the players you can see. The characteristics of a piece, and the differences between multiple performances of the same piece. The background stories behind a piece, and the way it is perceived by different types of audiences. Through smart use of technology, we want to use this richness to build a whole new classical concert experience. A concert experience that can guide you through a performance, with information tailored to varying expertise levels. A concert experience that allows you to get an impression of a piece before a concert, enriches the experience during a concert, and lets you revisit the concert after it was played, allowing you to discover new things about it. A concert experience that even may initiate a social discussion based on your impressions and the impressions of other attendees. All of this is not meant to defy the traditional concert experience, but to offer you new engaging experiences on top of it.


### 2011-2013
[![Shake-it]({{ site.url }}/images/shake-it.png)][2]

What are the properties of sound signals that induce the experience of groove in listeners? In particular, how do systematic patterns of signal properties (timing, metrical structure, loudness, etc.) relate to the experience of groove at several levels of the metrical structure?

To answer these questions, in ShakeIt, we follow an analysis/synthesis approach, and explore complementarities between three lines of work:

* Automatic analysis of groove features from audio. In particular, focusing on automatic learning from examples of what we call the “groove archetype” of certain music styles.

* Empirical experiments with human participants to validate/invalidate these features and to investigate if there are other relevant features for the perception of groove.

* Implementation of a software for real-time generation/manipulation of polyphonic rhythmic sequences conveying the groove of a certain style, or to gradually change the groove feel of a rhythmic sequence at run time.


 [1]: https://phenicx.upf.edu/
 [2]: https://smc.inesctec.pt/shakeit/
 [3]: https://ec.europa.eu/jrc/communities/community/humaint
 [4]: https://mtg.upf.edu/
 [5]: https://earthspeciesproject.org/
 [6]: #
