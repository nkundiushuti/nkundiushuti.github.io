---
layout: page
sidebar: right
subheadline: ""
title: "PyData Barcelona 2017"
teaser: "Deep learning workshop presented at PyData..."
header:
    image_fullwidth: "mediaplayer_js-home.jpg"
categories:
  - blog
tags:
  - coding, python
---
I presented a workshop on [convolutional neural networks for audio processing][19] at the PyData conference in Barcelona, along with my colleague Olga Slizovskaia. We introduced basic [data processing][18] routines with numpy and scipy, and then hyper-parameter visualization using TensorBoard. The introductory slides for the presentation can be found [here][20]. These routines are at the core of the source separation repository [DeepConvSep][21] and allowed me to train my model with hundreds of Gb of data.

During the three days of workshops and presentations, I learned a lot. I will try to summarize the things which I have seen.

I liked the tricks to speedup data reading and processing, given by [Guillerm Borell][1]. [Numexpr][2] is faster than numpy when performing different computations on big arrays. More speedup can be achieved with [numba][4], which compiles python code into native machine instructions, either on the CPU or GPU. Think of it like cython on steroids. Don't believe me? Try the python [timing and profiling routines][3]. Then, I was happy to find out that I am not the only one storing data as binary. I actually wrote my own [routines][7] for that, but if you look for something more fancy and also compatible with pandas, check [h5py][6]. Speaking of that, the following workshop by [Francesc Alted][8] was also very cool. Very similar to h5py, you can find [feather][9] which is a very fast format to store data. If you want something better for big data, check out [fastparquet][10].

During the second and the third day, I have attended a few talks. Yufeng Guo is a developer advocate at Google and he gave a talk about [wide and deep architectures][11] with TensorFlow. This talk is largely based on a [workshop][12] they did last year. I am not working on natural language processing but this talk and the talk by [Pascal van Kooten][14] on creating boots were interesting.

Then, I attented the keynote by [Gema Parre√±o][13] who won the [NASA asteroid challenge][15]. I really liked the slides on the classification of neural networks, [neural network zoo][16] and [Tensor playground][17] which does some basic simulations for various architectures and problems.

 [1]: https://pydata.org/barcelona2017/schedule/presentation/8/
 [2]: https://pypi.python.org/pypi/numexpr
 [3]: http://pynash.org/2013/03/06/timing-and-profiling/
 [4]: http://numba.pydata.org/
 [5]: https://github.com/guillemborrell/PyDataBCN
 [6]: http://www.h5py.org/
 [7]: https://github.com/nkundiushuti/pydata2017bcn/blob/master/util.py
 [8]: https://github.com/FrancescAlted/PyData-BCN
 [9]: https://blog.rstudio.org/2016/03/29/feather/
 [10]: https://www.continuum.io/blog/developer-blog/introducing-fastparquet
 [11]: https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/wide_n_deep/wide_n_deep_flow2.ipynb
 [12]: https://github.com/amygdala/tensorflow-workshop
 [13]: https://github.com/SoyGema
 [14]: https://github.com/kootenpv?tab=repositories
 [15]: https://open.nasa.gov/innovation-space/deep-asteroid/
 [16]: http://www.asimovinstitute.org/neural-network-zoo/
 [17]: http://playground.tensorflow.org/
 [18]: https://github.com/nkundiushuti/pydata2017bcn/blob/master/DataPreprocessing_results.ipynb
 [19]: https://github.com/nkundiushuti/pydata2017bcn/
 [20]: https://docs.google.com/presentation/d/1yTD8WYpovd5g_kfehGp-sq_Cxi5MEE1x7rUtmIzAhDA/edit?usp=sharing
 [21]: https://github.com/MTG/DeepConvSep

